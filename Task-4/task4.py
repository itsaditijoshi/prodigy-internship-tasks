# -*- coding: utf-8 -*-
"""task4.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1oo61lMn9NNiUZq4ARqY5Cv_VL_gmNcdI
"""

import zipfile

# Replace with your actual uploaded filename if different
zip_path = 'data (2).zip'

with zipfile.ZipFile(zip_path, 'r') as zip_ref:
    zip_ref.extractall()

import os
import cv2
import numpy as np

# Label map (from folder names)
gesture_labels = ['palm', 'l', 'fist', 'fist_moved', 'thumb', 'index', 'ok', 'palm_moved', 'c', 'down']
label_map = {name: i for i, name in enumerate(gesture_labels)}

X = []
y = []

# Adjust if folder name is slightly different
base_path = 'data'

for user_folder in os.listdir(base_path):
    user_path = os.path.join(base_path, user_folder)
    if not os.path.isdir(user_path):
        continue
    for gesture_name in os.listdir(user_path):
        gesture_path = os.path.join(user_path, gesture_name)
        if not os.path.isdir(gesture_path):
            continue
        gesture_clean = gesture_name.split('_')[-1]  # âœ… '01_palm' â†’ 'palm'
        if gesture_clean not in label_map:
            continue
        label = label_map[gesture_clean]
        for img_name in os.listdir(gesture_path):
            img_path = os.path.join(gesture_path, img_name)
            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)
            img = cv2.resize(img, (64, 64))
            X.append(img)
            y.append(label)

from sklearn.model_selection import train_test_split
from tensorflow.keras.utils import to_categorical

# Normalize pixel values (0â€“1)
X = np.array(X) / 255.0
y = np.array(y)

# For traditional ML: flatten the 64x64 images
X_flat = X.reshape(X.shape[0], -1)

# For CNN: add channel dimension
X_cnn = X.reshape(-1, 64, 64, 1)
y_cnn = to_categorical(y, num_classes=10)

# Split data
X_train_flat, X_test_flat, y_train_flat, y_test_flat = train_test_split(X_flat, y, test_size=0.2, random_state=42)
X_train_cnn, X_test_cnn, y_train_cnn, y_test_cnn = train_test_split(X_cnn, y_cnn, test_size=0.2, random_state=42)

from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report

rf = RandomForestClassifier(n_estimators=100, random_state=42)
rf.fit(X_train_flat, y_train_flat)

y_pred_rf = rf.predict(X_test_flat)

print("ðŸŽ¯ Random Forest Accuracy:", accuracy_score(y_test_flat, y_pred_rf))
print("\nClassification Report:\n", classification_report(y_test_flat, y_pred_rf))

import matplotlib.pyplot as plt

# Map class indices to gesture labels
gesture_labels = ['palm', 'l', 'fist', 'fist_moved', 'thumb', 'index', 'ok', 'palm_moved', 'c', 'down']

# Pick a few test samples to visualize
num_samples = 12
plt.figure(figsize=(12, 8))

for i in range(num_samples):
    plt.subplot(3, 4, i + 1)
    image = X_test_flat[i].reshape(64, 64)  # reshape flat image back to 64x64
    plt.imshow(image, cmap='gray')

    pred_label = gesture_labels[y_pred_rf[i]]
    true_label = gesture_labels[y_test_flat[i]]

    color = 'green' if pred_label == true_label else 'red'

    plt.title(f'Pred: {pred_label}\nTrue: {true_label}', color=color, fontsize=10)
    plt.axis('off')

plt.tight_layout()
plt.show()

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense

cnn = Sequential([
    Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, 1)),
    MaxPooling2D(2, 2),
    Conv2D(64, (3, 3), activation='relu'),
    MaxPooling2D(2, 2),
    Flatten(),
    Dense(128, activation='relu'),
    Dense(10, activation='softmax')
])

cnn.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
cnn.fit(X_train_cnn, y_train_cnn, epochs=10, validation_data=(X_test_cnn, y_test_cnn))

cnn_loss, cnn_acc = cnn.evaluate(X_test_cnn, y_test_cnn)
print("ðŸŽ¯ CNN Accuracy:", cnn_acc)

import matplotlib.pyplot as plt
import numpy as np

# Map class indices to gesture labels
gesture_labels = ['palm', 'l', 'fist', 'fist_moved', 'thumb', 'index', 'ok', 'palm_moved', 'c', 'down']

# Number of samples to show
num_samples = 12
plt.figure(figsize=(12, 8))

# Predict labels for test set
cnn_preds = cnn.predict(X_test_cnn)

for i in range(num_samples):
    plt.subplot(3, 4, i + 1)

    image = X_test_cnn[i].reshape(64, 64)
    true_label = np.argmax(y_test_cnn[i])
    pred_label = np.argmax(cnn_preds[i])

    plt.imshow(image, cmap='gray')
    color = 'green' if pred_label == true_label else 'red'
    plt.title(f"Pred: {gesture_labels[pred_label]}\nTrue: {gesture_labels[true_label]}", color=color, fontsize=10)
    plt.axis('off')

plt.tight_layout()
plt.show()